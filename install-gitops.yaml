- name: Install OpenShift GitOps Operator
  hosts: localhost
  gather_facts: true
  vars:
    gitops_operator_name: openshift-gitops-operator
    gitops_subscription_name: openshift-gitops-operator
    gitops_namespace: openshift-operators
    gitops_target_namespace: openshift-gitops
    gitops_csv_prefix: openshift-gitops-operator
    gitops_csv_version: "1.19.1"
    gitops_channel: "gitops-1.19"
    gitops_already_installed: false

  tasks:
    - name: Check if oc CLI is available
      command: which oc
      register: oc_check
      changed_when: false
      failed_when: false

    - name: Fail if oc CLI is not found
      fail:
        msg: "oc (OpenShift CLI) is not installed. Please install it first."
      when: oc_check.rc != 0

    - name: Get current OpenShift user
      command: oc whoami
      register: oc_user
      changed_when: false

    - name: Display authenticated user
      debug:
        msg: "Authenticated as: {{ oc_user.stdout }}"

    - name: Get cluster domain
      command: oc get ingress.config/cluster -o jsonpath='{.spec.domain}'
      register: cluster_domain_result
      changed_when: false
      failed_when: false

    - name: Set cluster domain
      set_fact:
        cluster_domain: "{{ cluster_domain_result.stdout }}"
      when: cluster_domain_result.rc == 0 and cluster_domain_result.stdout | length > 0

    - name: Prompt for cluster domain if not detected
      set_fact:
        cluster_domain: "{{ lookup('env', 'CLUSTER_DOMAIN') | default('', true) }}"
      when: cluster_domain is not defined or cluster_domain == ""

    - name: Fail if cluster domain is not set
      fail:
        msg: "Cluster domain is required. Set CLUSTER_DOMAIN environment variable or ensure cluster is accessible."
      when: cluster_domain is not defined or cluster_domain == ""

    - name: Check if OpenShift GitOps is already installed
      k8s_info:
        api_version: argoproj.io/v1alpha1
        kind: ArgoCD
        namespace: openshift-gitops
        name: openshift-gitops
      register: gitops_existing_check
      failed_when: false
      changed_when: false

    - name: Set gitops_already_installed when ArgoCD is present and Available
      set_fact:
        gitops_already_installed: "{{ (gitops_existing_check.resources | default([]) | length > 0) and ((gitops_existing_check.resources | default([]) | first).status.phase | default('') == 'Available') }}"

    - name: Display GitOps already installed, skipping operator installation
      debug:
        msg: "OpenShift GitOps is already installed and available. Skipping operator installation."
      when: gitops_already_installed | default(false) | bool

    - name: Construct apps domain
      set_fact:
        apps_domain: "{{ 'apps.' + cluster_domain if not cluster_domain.startswith('apps.') else cluster_domain }}"
        keycloak_host: "rhbk.{{ 'apps.' + cluster_domain if not cluster_domain.startswith('apps.') else cluster_domain }}"
        app_host: "neuralbank.{{ 'apps.' + cluster_domain if not cluster_domain.startswith('apps.') else cluster_domain }}"

    - name: Display cluster information
      debug:
        msg:
          - "Cluster domain: {{ cluster_domain }}"
          - "Apps domain: {{ apps_domain }}"
          - "Keycloak host: {{ keycloak_host }}"
          - "App host: {{ app_host }}"

    - name: Replace KEYCLOAK_HOST_PLACEHOLDER and APP_HOST_PLACEHOLDER in repo files (dynamic cluster domain)
      block:
        - name: Replace placeholders in neuralbank-stack/values.yaml
          replace:
            path: "{{ playbook_dir }}/neuralbank-stack/values.yaml"
            regexp: "KEYCLOAK_HOST_PLACEHOLDER"
            replace: "{{ keycloak_host }}"
        - name: Replace APP_HOST_PLACEHOLDER in neuralbank-stack/values.yaml
          replace:
            path: "{{ playbook_dir }}/neuralbank-stack/values.yaml"
            regexp: "APP_HOST_PLACEHOLDER"
            replace: "{{ app_host }}"
        - name: Replace placeholders in rhcl-operator/oidc-policy.yaml
          replace:
            path: "{{ playbook_dir }}/rhcl-operator/oidc-policy.yaml"
            regexp: "KEYCLOAK_HOST_PLACEHOLDER"
            replace: "{{ keycloak_host }}"
        - name: Replace APP_HOST_PLACEHOLDER in rhcl-operator/oidc-policy.yaml
          replace:
            path: "{{ playbook_dir }}/rhcl-operator/oidc-policy.yaml"
            regexp: "APP_HOST_PLACEHOLDER"
            replace: "{{ app_host }}"
        - name: Replace placeholders in rhbk/keycloak-neuralbank-realm.yaml
          replace:
            path: "{{ playbook_dir }}/rhbk/keycloak-neuralbank-realm.yaml"
            regexp: "KEYCLOAK_HOST_PLACEHOLDER"
            replace: "{{ keycloak_host }}"
        - name: Replace APP_HOST_PLACEHOLDER in rhbk/keycloak-neuralbank-realm.yaml
          replace:
            path: "{{ playbook_dir }}/rhbk/keycloak-neuralbank-realm.yaml"
            regexp: "APP_HOST_PLACEHOLDER"
            replace: "{{ app_host }}"
        - name: Replace APP_HOST_PLACEHOLDER in rhcl-operator/neuralbank-route.yaml
          replace:
            path: "{{ playbook_dir }}/rhcl-operator/neuralbank-route.yaml"
            regexp: "APP_HOST_PLACEHOLDER"
            replace: "{{ app_host }}"
        - name: Replace APP_HOST_PLACEHOLDER in rhcl-operator/neuralbank-oidc-callback.yaml
          replace:
            path: "{{ playbook_dir }}/rhcl-operator/neuralbank-oidc-callback.yaml"
            regexp: "APP_HOST_PLACEHOLDER"
            replace: "{{ app_host }}"
      when: keycloak_host is defined and app_host is defined

    - name: Install OpenShift GitOps operator and wait for ArgoCD
      block:
        - name: Ensure openshift-operators namespace exists
          k8s:
            name: "{{ gitops_namespace }}"
            api_version: v1
            kind: Namespace
            state: present

        - name: Check if OperatorGroup exists
          k8s_info:
            api_version: operators.coreos.com/v1alpha2
            kind: OperatorGroup
            namespace: "{{ gitops_namespace }}"
            name: global-operators
          register: operatorgroup_check

        - name: Create OperatorGroup if it doesn't exist
          k8s:
            api_version: operators.coreos.com/v1alpha2
            kind: OperatorGroup
            name: global-operators
            namespace: "{{ gitops_namespace }}"
            state: present
            definition:
              spec: {}
          when: operatorgroup_check.resources | length == 0

        - name: Check CatalogSource health
          k8s_info:
            api_version: operators.coreos.com/v1alpha1
            kind: CatalogSource
            namespace: openshift-marketplace
            name: redhat-operators
          register: catalogsource_info

        - name: Display CatalogSource status
          debug:
            msg:
              - "CatalogSource status: {{ catalogsource_info.resources[0].status.connectionState.lastObservedState | default('Unknown') }}"
              - "CatalogSource ready: {{ catalogsource_info.resources[0].status.conditions | selectattr('type', 'equalto', 'Ready') | map(attribute='status') | first | default('Unknown') }}"
          when: catalogsource_info.resources | length > 0

        - name: Get current timestamp for CatalogSource update
          set_fact:
            force_update_timestamp: "{{ ansible_facts['date_time']['epoch'] }}"
          when: catalogsource_info.resources | length > 0 and 
            (catalogsource_info.resources[0].status.connectionState.lastObservedState | default('') != 'READY' or
             catalogsource_info.resources[0].status.conditions | selectattr('type', 'equalto', 'Ready') | map(attribute='status') | first | default('False') != 'True')

        - name: Force CatalogSource update if needed
          command: >
            oc patch catalogsource redhat-operators
            -n openshift-marketplace
            --type=merge
            -p '{"metadata":{"annotations":{"olm.catalogSource.forceUpdate":"{{ force_update_timestamp }}"}}}'
          when: catalogsource_info.resources | length > 0 and 
            (catalogsource_info.resources[0].status.connectionState.lastObservedState | default('') != 'READY' or
             catalogsource_info.resources[0].status.conditions | selectattr('type', 'equalto', 'Ready') | map(attribute='status') | first | default('False') != 'True')
          register: catalogsource_patch_result
          changed_when: catalogsource_patch_result.rc == 0

        - name: Wait for CatalogSource to be ready
          k8s_info:
            api_version: operators.coreos.com/v1alpha1
            kind: CatalogSource
            namespace: openshift-marketplace
            name: redhat-operators
          register: catalogsource_ready
          until: >
            catalogsource_ready.resources | length > 0 and
            catalogsource_ready.resources[0].status.connectionState.lastObservedState | default('') == 'READY'
          retries: 30
          delay: 5
          failed_when: false
          when: catalogsource_info.resources | length > 0

        - name: Check if subscription already exists
          k8s_info:
            api_version: operators.coreos.com/v1alpha1
            kind: Subscription
            namespace: "{{ gitops_namespace }}"
            name: "{{ gitops_subscription_name }}"
          register: subscription_check

        - name: Delete existing subscription if it has issues
          k8s:
            api_version: operators.coreos.com/v1alpha1
            kind: Subscription
            namespace: "{{ gitops_namespace }}"
            name: "{{ gitops_subscription_name }}"
            state: absent
          when: >
            subscription_check.resources | length > 0 and
            (subscription_check.resources[0].status.conditions | selectattr('type', 'equalto', 'CatalogSourcesUnhealthy') | map(attribute='status') | first | default('False') == 'True' or
             subscription_check.resources[0].status.conditions | selectattr('type', 'equalto', 'ResolutionFailed') | map(attribute='status') | first | default('False') == 'True')

        - name: Get available channels for operator
          command: >
            oc get packagemanifests {{ gitops_operator_name }}
            -n openshift-marketplace
            -o jsonpath='{.status.channels[*].name}'
          register: available_channels_list
          failed_when: false
          changed_when: false

        - name: Get CSV for gitops-1.19 channel
          command: >
            oc get packagemanifests {{ gitops_operator_name }}
            -n openshift-marketplace
            -o jsonpath='{.status.channels[?(@.name=="gitops-1.19")].currentCSV}'
          register: csv_1_19
          failed_when: false
          changed_when: false
          when: >
            available_channels_list.rc == 0 and
            'gitops-1.19' in available_channels_list.stdout

        - name: Set CSV name from gitops-1.19 channel
          set_fact:
            gitops_starting_csv: "{{ csv_1_19.stdout }}"
          when: >
            csv_1_19.rc == 0 and
            csv_1_19.stdout | length > 0

        - name: Display target CSV
          debug:
            msg: "Target CSV: {{ gitops_starting_csv }}"
          when: gitops_starting_csv is defined

        - name: Create or update Subscription (channel only, no startingCSV – OLM picks version; installPlanApproval Automatic)
          k8s:
            api_version: operators.coreos.com/v1alpha1
            kind: Subscription
            name: "{{ gitops_subscription_name }}"
            namespace: "{{ gitops_namespace }}"
            state: present
            definition:
              spec:
                channel: "{{ gitops_channel }}"
                name: "{{ gitops_operator_name }}"
                source: redhat-operators
                sourceNamespace: openshift-marketplace
                installPlanApproval: Automatic

        - name: Check subscription status
          k8s_info:
            api_version: operators.coreos.com/v1alpha1
            kind: Subscription
            namespace: "{{ gitops_namespace }}"
            name: "{{ gitops_subscription_name }}"
          register: subscription_status
          failed_when: false

        - name: Display subscription status
          debug:
            msg:
              - "Subscription conditions:"
              - "{{ subscription_status.resources[0].status.conditions | default([]) | map(attribute='type') | list }}"
          when: >
            subscription_status.resources | length > 0 and
            subscription_status.resources[0].status is defined and
            subscription_status.resources[0].status.conditions is defined

        - name: Check for ResolutionFailed condition
          debug:
            msg: "Subscription has ResolutionFailed condition. This usually means the operator is not available in the specified channel. Trying to find available channels..."
          when: >
            subscription_status.resources | length > 0 and
            subscription_status.resources[0].status is defined and
            subscription_status.resources[0].status.conditions is defined and
            (subscription_status.resources[0].status.conditions | 
             selectattr('type', 'equalto', 'ResolutionFailed') | 
             selectattr('status', 'equalto', 'True') | 
             list | length > 0)

        - name: Get available channels for operator
          command: >
            oc get packagemanifests openshift-gitops-operator
            -n openshift-marketplace
            -o jsonpath='{.status.channels[*].name}'
          register: available_channels
          failed_when: false
          changed_when: false
          when: >
            subscription_status.resources | length > 0 and
            subscription_status.resources[0].status is defined and
            subscription_status.resources[0].status.conditions is defined and
            (subscription_status.resources[0].status.conditions | 
             selectattr('type', 'equalto', 'ResolutionFailed') | 
             selectattr('status', 'equalto', 'True') | 
             list | length > 0)

        - name: Display available channels
          debug:
            msg: "Available channels: {{ available_channels.stdout | default('Not found') }}"
          when: >
            available_channels is defined and
            available_channels.rc is defined and
            available_channels.rc == 0 and
            available_channels.stdout is defined and
            available_channels.stdout | length > 0

        - name: Update subscription to use latest channel if stable not available
          k8s:
            api_version: operators.coreos.com/v1alpha1
            kind: Subscription
            name: "{{ gitops_subscription_name }}"
            namespace: "{{ gitops_namespace }}"
            state: present
            definition:
              spec:
                channel: "{{ (available_channels.stdout | default('stable')).split(' ') | first }}"
                name: "{{ gitops_operator_name }}"
                source: redhat-operators
                sourceNamespace: openshift-marketplace
                installPlanApproval: Automatic
          when: >
            available_channels is defined and
            available_channels.rc is defined and
            available_channels.rc == 0 and
            available_channels.stdout is defined and
            available_channels.stdout | length > 0 and
            'stable' not in available_channels.stdout

        - name: Wait for InstallPlan to be created (with fallback if pinned version unavailable)
          block:
            - name: Check subscription status for InstallPlan
              k8s_info:
                api_version: operators.coreos.com/v1alpha1
                kind: Subscription
                namespace: "{{ gitops_namespace }}"
                name: "{{ gitops_subscription_name }}"
              register: subscription_status_final
              until: >
                (subscription_status_final.resources | default([]) | length > 0) and
                (subscription_status_final.resources[0].status is defined) and
                (subscription_status_final.resources[0].status.installPlanRef is defined and
                 subscription_status_final.resources[0].status.installPlanRef.name is defined)
              retries: 45
              delay: 15
              failed_when: false

            - name: Display subscription status for debugging
              debug:
                msg:
                  - "Subscription status check:"
                  - "  - Subscription exists: {{ (subscription_status_final.resources | default([])) | length > 0 }}"
                  - "  - Has status: {{ (subscription_status_final.resources | default([]) | length > 0) and (subscription_status_final.resources[0].status is defined) }}"
                  - "  - Has installPlanRef: {{ (subscription_status_final.resources | default([]) | length > 0) and (subscription_status_final.resources[0].status.installPlanRef is defined) }}"
                  - "  - Conditions: {{ subscription_status_final.resources[0].status.conditions | default([]) | map(attribute='type') | list }}"
              when: (subscription_status_final.resources | default([])) | length > 0

            - name: Check for subscription errors
              debug:
                msg:
                  - "Subscription error detected:"
                  - "{{ subscription_status_final.resources[0].status.conditions | default([]) | selectattr('status', 'equalto', 'True') | selectattr('type', 'in', ['ResolutionFailed', 'CatalogSourcesUnhealthy', 'InstallPlanMissing']) | map(attribute='message') | list }}"
              when: >
                (subscription_status_final.resources | default([]) | length > 0) and
                subscription_status_final.resources[0].status is defined and
                subscription_status_final.resources[0].status.conditions is defined and
                (subscription_status_final.resources[0].status.conditions |
                 selectattr('status', 'equalto', 'True') |
                 selectattr('type', 'in', ['ResolutionFailed', 'CatalogSourcesUnhealthy', 'InstallPlanMissing']) |
                 list | length > 0)

            - name: Check for InstallPlans directly in namespace
              k8s_info:
                api_version: operators.coreos.com/v1alpha1
                kind: InstallPlan
                namespace: "{{ gitops_namespace }}"
              register: installplans_direct
              failed_when: false
              when: >
                (subscription_status_final.resources | default([]) | length == 0) or
                subscription_status_final.resources[0].status is not defined or
                subscription_status_final.resources[0].status.installPlanRef is not defined or
                subscription_status_final.resources[0].status.installPlanRef.name is not defined

            - name: Use InstallPlan found directly if subscription doesn't have reference
              set_fact:
                install_plan_name: "{{ installplans_direct.resources[0].metadata.name }}"
              when: >
                (installplans_direct.resources | default([]) | length > 0) and
                ((subscription_status_final.resources | default([]) | length == 0) or
                 subscription_status_final.resources[0].status is not defined or
                 subscription_status_final.resources[0].status.installPlanRef is not defined or
                 subscription_status_final.resources[0].status.installPlanRef.name is not defined)

            - name: Fail if InstallPlan not created after retries
              fail:
                msg: >
                  InstallPlan was not created after 45 retries (~11 minutes).
                  If you see "resolving" with status "Unknown" in subscription/InstallPlan output, OLM may still be
                  resolving dependencies—wait 5–10 minutes and re-run the playbook (./install.sh).
                  Other causes:
                  - CatalogSource is not ready or unhealthy
                  - Operator is not available in the specified channel ({{ gitops_channel }})
                  - Network issues preventing access to the operator catalog
                  
                  Troubleshooting steps:
                  1. Check subscription: oc get subscription {{ gitops_subscription_name }} -n {{ gitops_namespace }} -o yaml
                  2. Check subscription conditions: oc describe subscription {{ gitops_subscription_name }} -n {{ gitops_namespace }}
                  3. Check InstallPlans: oc get installplan -n {{ gitops_namespace }}
                  4. Check CatalogSource: oc get catalogsource redhat-operators -n openshift-marketplace
                  5. Check operator availability: oc get packagemanifests {{ gitops_operator_name }} -n openshift-marketplace
              when: >
                ((subscription_status_final.resources | default([]) | length == 0) or
                 ((subscription_status_final.resources | default([]) | length > 0) and
                  (subscription_status_final.resources[0].status is not defined or
                   subscription_status_final.resources[0].status.installPlanRef is not defined or
                   subscription_status_final.resources[0].status.installPlanRef.name is not defined))) and
                (installplans_direct.resources is not defined or (installplans_direct.resources | default([]) | length == 0))

          rescue:
            - name: Fallback - InstallPlan not created with pinned version
              debug:
                msg: "Trying fallback: subscription without version pin (use latest from catalog)"

            - name: Get available channels for fallback
              command: >
                oc get packagemanifests {{ gitops_operator_name }} -n openshift-marketplace
                -o jsonpath='{.status.channels[*].name}'
              register: fallback_channels
              changed_when: false
              failed_when: false

            - name: Set fallback channel
              set_fact:
                fallback_channel: "{{ (fallback_channels.stdout | default('stable')).split() | first }}"

            - name: Remove startingCSV from subscription so OLM resolves latest in channel
              command: >
                oc patch subscription {{ gitops_subscription_name }}
                -n {{ gitops_namespace }}
                --type=json
                -p '[{"op": "remove", "path": "/spec/startingCSV"}]'
              register: remove_starting_csv
              failed_when: false
              changed_when: remove_starting_csv.rc == 0

            - name: Update subscription to fallback channel (no startingCSV)
              k8s:
                api_version: operators.coreos.com/v1alpha1
                kind: Subscription
                name: "{{ gitops_subscription_name }}"
                namespace: "{{ gitops_namespace }}"
                state: present
                definition:
                  spec:
                    channel: "{{ fallback_channel }}"
                    name: "{{ gitops_operator_name }}"
                    source: redhat-operators
                    sourceNamespace: openshift-marketplace
                    installPlanApproval: Automatic

            - name: Wait for InstallPlan (fallback)
              k8s_info:
                api_version: operators.coreos.com/v1alpha1
                kind: Subscription
                namespace: "{{ gitops_namespace }}"
                name: "{{ gitops_subscription_name }}"
              register: subscription_status_final
              until: >
                (subscription_status_final.resources | default([]) | length > 0) and
                (subscription_status_final.resources[0].status is defined) and
                (subscription_status_final.resources[0].status.installPlanRef is defined and
                 subscription_status_final.resources[0].status.installPlanRef.name is defined)
              retries: 45
              delay: 15
              failed_when: false

            - name: Set install_plan_name from fallback subscription
              set_fact:
                install_plan_name: "{{ subscription_status_final.resources[0].status.installPlanRef.name }}"
              when: >
                (subscription_status_final.resources | default([]) | length > 0) and
                subscription_status_final.resources[0].status is defined and
                subscription_status_final.resources[0].status.installPlanRef is defined and
                subscription_status_final.resources[0].status.installPlanRef.name is defined

            - name: Get InstallPlans directly (fallback)
              k8s_info:
                api_version: operators.coreos.com/v1alpha1
                kind: InstallPlan
                namespace: "{{ gitops_namespace }}"
              register: installplans_direct
              failed_when: false
              when: install_plan_name is not defined

            - name: Set install_plan_name from direct list (fallback)
              set_fact:
                install_plan_name: "{{ installplans_direct.resources[0].metadata.name }}"
              when: >
                install_plan_name is not defined and
                (installplans_direct.resources | default([]) | length > 0)

            - name: Debug subscription and InstallPlans when fallback did not create InstallPlan
              block:
                - name: Get subscription and InstallPlans for debugging
                  command: >
                    oc get subscription {{ gitops_subscription_name }} -n {{ gitops_namespace }} -o yaml
                  register: sub_yaml
                  changed_when: false
                  failed_when: false

                - name: List InstallPlans in namespace
                  command: oc get installplan -n {{ gitops_namespace }} -o wide
                  register: ip_list
                  changed_when: false
                  failed_when: false

                - name: Show subscription status (fallback failed)
                  debug:
                    msg:
                      - "Subscription (last 50 lines):"
                      - "{{ (sub_yaml.stdout_lines | default([]))[-50:] | join('\n') }}"
                  when: sub_yaml.stdout is defined and sub_yaml.stdout | length > 0

                - name: Show InstallPlan list (fallback failed)
                  debug:
                    msg: "InstallPlans in {{ gitops_namespace }}: {{ ip_list.stdout | default('(none or error)') }}"
              when: install_plan_name is not defined

            - name: Fail if InstallPlan still not created after fallback
              fail:
                msg: >
                  InstallPlan was not created even after fallback (subscription without version pin, waited ~11 min).
                  If output shows "resolving" with status "Unknown", OLM may still be resolving—wait and re-run ./install.sh.
                  Check subscription conditions and catalog:
                  oc get subscription {{ gitops_subscription_name }} -n {{ gitops_namespace }} -o yaml
                  oc describe subscription {{ gitops_subscription_name }} -n {{ gitops_namespace }}
                  oc get installplan -n {{ gitops_namespace }}
                  oc get catalogsource redhat-operators -n openshift-marketplace -o yaml
              when: install_plan_name is not defined

        - name: Get InstallPlan name
          set_fact:
            install_plan_name: "{{ subscription_status_final.resources[0].status.installPlanRef.name }}"
          when: >
            (subscription_status_final.resources | default([]) | length > 0) and
            subscription_status_final.resources[0].status is defined and
            subscription_status_final.resources[0].status.installPlanRef is defined and
            subscription_status_final.resources[0].status.installPlanRef.name is defined

        - name: Wait for InstallPlan to be approved
          k8s_info:
            api_version: operators.coreos.com/v1alpha1
            kind: InstallPlan
            namespace: "{{ gitops_namespace }}"
            name: "{{ install_plan_name }}"
          register: installplan_status
          until: >
            (installplan_status.resources | default([]) | length > 0) and
            installplan_status.resources[0].spec.approved == true
          retries: 10
          delay: 2
          when: install_plan_name is defined

        - name: Approve InstallPlan if not approved
          command: >
            oc patch installplan {{ install_plan_name }}
            -n {{ gitops_namespace }}
            --type=merge
            -p '{"spec":{"approved":true}}'
          when: >
            install_plan_name is defined and
            (installplan_status.resources | default([]) | length > 0) and
            installplan_status.resources[0].spec.approved != true
          register: installplan_patch_result
          changed_when: installplan_patch_result.rc == 0

        - name: Wait for InstallPlan to complete (OLM finished applying resources)
          k8s_info:
            api_version: operators.coreos.com/v1alpha1
            kind: InstallPlan
            namespace: "{{ gitops_namespace }}"
            name: "{{ install_plan_name }}"
          register: installplan_complete
          until: >
            (installplan_complete.resources | default([]) | length > 0) and
            ((installplan_complete.resources[0].status.phase | default('')) == 'Complete')
          retries: 60
          delay: 10
          failed_when: false
          when: install_plan_name is defined

        - name: Wait for CSV to be installed and ready
          k8s_info:
            api_version: operators.coreos.com/v1alpha1
            kind: ClusterServiceVersion
            namespace: "{{ gitops_namespace }}"
          register: csv_list
          until: >
            (csv_list.resources | default([]) | length > 0) and
            ((csv_list.resources | default([])) |
             selectattr('metadata.name', 'search', gitops_csv_prefix) |
             selectattr('status.phase', 'equalto', 'Succeeded') |
             list | length > 0)
          retries: 90
          delay: 10
          failed_when: false

        - name: Get CSV name
          set_fact:
            csv_name: "{{ (csv_list.resources | default([])) | selectattr('metadata.name', 'search', gitops_csv_prefix) | selectattr('status.phase', 'equalto', 'Succeeded') | map(attribute='metadata.name') | first }}"
          when: >
            (csv_list.resources | default([]) | length > 0) and
            ((csv_list.resources | default([])) |
             selectattr('metadata.name', 'search', gitops_csv_prefix) |
             selectattr('status.phase', 'equalto', 'Succeeded') |
             list | length > 0)

        - name: Display CSV status
          debug:
            msg: "CSV {{ csv_name }} is installed and ready"
          when: csv_name is defined

        - name: Check if CSV installation failed
          fail:
            msg: >
              CSV from channel {{ gitops_channel }} did not reach Succeeded after 90 retries (~15 min).
              If OLM was still "resolving" (status Unknown), wait 5–10 minutes and re-run ./install.sh.
              Check CSV status: oc get csv -n {{ gitops_namespace }} | grep {{ gitops_csv_prefix }}
              Check InstallPlan: oc get installplan -n {{ gitops_namespace }} -o wide
          when: >
            (csv_list.resources | default([]) | length == 0) or
            ((csv_list.resources | default([])) |
             selectattr('metadata.name', 'search', gitops_csv_prefix) |
             selectattr('status.phase', 'equalto', 'Succeeded') |
             list | length == 0)

        - name: Wait for openshift-gitops namespace to be created
          k8s_info:
            api_version: v1
            kind: Namespace
            name: "{{ gitops_target_namespace }}"
          register: gitops_namespace_check
          until: gitops_namespace_check.resources | length > 0
          retries: 30
          delay: 5
          failed_when: false

        - name: Check if ArgoCD CRD exists
          command: oc get crd argocds.argoproj.io
          register: argocd_crd_check
          failed_when: false
          changed_when: false

        - name: Wait for ArgoCD CRD to be available
          command: oc get crd argocds.argoproj.io
          register: argocd_crd_available
          until: argocd_crd_available.rc == 0
          retries: 30
          delay: 5
          failed_when: false

        - name: Check if ArgoCD instance exists and is available
          k8s_info:
            api_version: argoproj.io/v1alpha1
            kind: ArgoCD
            namespace: "{{ gitops_target_namespace }}"
            name: openshift-gitops
          register: argocd_instance_check
          failed_when: false
          changed_when: false
          when: argocd_crd_available.rc == 0

        - name: Display ArgoCD instance status
          debug:
            msg:
              - "ArgoCD instance status:"
              - "  Phase: {{ (argocd_instance_check.resources | default([]) | first).status.phase | default('Unknown') }}"
              - "  Application Controller: {{ (argocd_instance_check.resources | default([]) | first).status.applicationController | default('Not available') }}"
              - "  Server: {{ (argocd_instance_check.resources | default([]) | first).status.server | default('Not available') }}"
          when: (argocd_instance_check.resources | default([]) | length) > 0

        - name: Wait for ArgoCD instance to be available
          k8s_info:
            api_version: argoproj.io/v1alpha1
            kind: ArgoCD
            namespace: "{{ gitops_target_namespace }}"
            name: openshift-gitops
          register: argocd_instance
          until: >
            (argocd_instance.resources | default([]) | length > 0) and
            ((argocd_instance.resources | default([]) | first).status.phase | default('') == 'Available')
          retries: 60
          delay: 5
          failed_when: false
          when: >
            argocd_crd_available.rc == 0 and
            ((argocd_instance_check.resources | default([]) | length == 0) or
             ((argocd_instance_check.resources | default([]) | first).status.phase | default('') != 'Available'))

        - name: Verify ArgoCD instance final status
          k8s_info:
            api_version: argoproj.io/v1alpha1
            kind: ArgoCD
            namespace: "{{ gitops_target_namespace }}"
            name: openshift-gitops
          register: argocd_final_check
          failed_when: false

        - name: Display installation success
          debug:
            msg:
              - "OpenShift GitOps Operator installed successfully!"
              - "CSV: {{ csv_name | default('Not found') }}"
              - "Namespace: {{ gitops_target_namespace }}"
              - "ArgoCD instance phase: {{ (argocd_final_check.resources | default([]) | first).status.phase | default('Unknown') if (argocd_final_check.resources | default([]) | length) > 0 else 'Instance not found' }}"
          when: csv_name is defined or (argocd_final_check.resources | default([]) | length) > 0

        - name: Display warning if ArgoCD not available
          debug:
            msg: "Warning: ArgoCD instance may not be fully available. Check with: oc get argocd openshift-gitops -n {{ gitops_target_namespace }}"
          when: >
            (argocd_final_check.resources | default([]) | length == 0) or
            ((argocd_final_check.resources | default([]) | first).status.phase | default('') != 'Available')
      when: not (gitops_already_installed | default(false) | bool)

    - name: Apply ApplicationSet and verify operators
      block:
        - name: Set ApplicationSet variables
          set_fact:
            applicationset_file: "{{ playbook_dir }}/applicationset-instance.yaml"
            gitops_namespace: openshift-gitops
            required_operators:
              - name: servicemeshoperator3
                namespace: openshift-operators
              - name: rhcl-operator
                namespace: openshift-operators
              - name: rhbk-operator
                namespace: rhbk-operator
              - name: rhdh-operator
                namespace: rhdh-operator
              - name: devspaces
                namespace: openshift-operators

        - name: Check if ApplicationSet file exists
          stat:
            path: "{{ applicationset_file }}"
          register: applicationset_file_stat

        - name: Fail if ApplicationSet file not found
          fail:
            msg: "ApplicationSet file not found: {{ applicationset_file }}"
          when: not applicationset_file_stat.stat.exists

        - name: Apply ApplicationSet
          command: oc apply -f "{{ applicationset_file }}"
          register: apply_applicationset_result
          failed_when: apply_applicationset_result.rc != 0

        - name: Display ApplicationSet status
          debug:
            msg: "ApplicationSet applied successfully"

        - name: Wait for ApplicationSet to create applications
          pause:
            seconds: 10

        - name: Check applications were created
          command: oc get applications -n "{{ gitops_namespace }}" --no-headers
          register: apps_check
          failed_when: false
          changed_when: false
          until: (apps_check.rc | default(1)) == 0 and (apps_check.stdout | default('') | length > 0)
          retries: 12
          delay: 5

        - name: Display applications
          command: oc get applications -n "{{ gitops_namespace }}"
          register: all_apps
          changed_when: false
          failed_when: false

        - name: Show applications status
          debug:
            msg: "{{ all_apps.stdout_lines }}"
          when: all_apps.rc == 0

        - name: Wait for operator subscriptions to be created
          pause:
            seconds: 15

        - name: Wait for required operator subscriptions to exist
          k8s_info:
            api_version: operators.coreos.com/v1alpha1
            kind: Subscription
            namespace: "{{ item.namespace }}"
            name: "{{ item.name }}"
          register: sub_check
          until: sub_check.resources | length > 0
          retries: 36
          delay: 10
          failed_when: false
          loop: "{{ required_operators }}"
          loop_control:
            label: "{{ item.name }} in {{ item.namespace }}"

        - name: Warn if any subscription still missing after wait
          debug:
            msg: "Subscription {{ item.item.name }} in {{ item.item.namespace }} still not found after wait. CSV wait may fail."
          loop: "{{ sub_check.results }}"
          loop_control:
            label: "{{ item.item.name }}"
          when: item.resources | length == 0

        - name: Verify required operators are being installed
          block:
            - name: Check operator subscription exists
              k8s_info:
                api_version: operators.coreos.com/v1alpha1
                kind: Subscription
                namespace: "{{ item.namespace }}"
                name: "{{ item.name }}"
              register: operator_subscription
              failed_when: false
              changed_when: false
              loop: "{{ required_operators }}"
              loop_control:
                label: "{{ item.name }} in {{ item.namespace }}"

            - name: Display operator subscription status
              debug:
                msg:
                  - "Operator: {{ item.item.name }}"
                  - "Namespace: {{ item.item.namespace }}"
                  - "Subscription exists: {{ item.resources | length > 0 }}"
                  - "Status: {{ item.resources[0].status | default('Not available') if item.resources | length > 0 else 'Not found' }}"
              loop: "{{ operator_subscription.results }}"
              loop_control:
                label: "{{ item.item.name }}"

          rescue:
            - name: Display error checking operator subscriptions
              debug:
                msg: "Error checking operator subscriptions. Continuing..."

        - name: Wait for operators to be installed and ready
          block:
            - name: Check operator CSV status
              k8s_info:
                api_version: operators.coreos.com/v1alpha1
                kind: ClusterServiceVersion
                namespace: "{{ item.namespace }}"
              register: operator_csvs
              failed_when: false
              changed_when: false
              loop: "{{ required_operators }}"
              loop_control:
                label: "{{ item.name }} in {{ item.namespace }}"

            - name: Wait for each operator CSV to be Succeeded
              k8s_info:
                api_version: operators.coreos.com/v1alpha1
                kind: ClusterServiceVersion
                namespace: "{{ item.namespace }}"
              register: csv_status
              until: >
                csv_status.resources | length > 0 and
                (csv_status.resources | selectattr('metadata.name', 'match', '.*' + item.name + '.*') | map(attribute='status.phase') | list | first | default('') == 'Succeeded')
              retries: 60
              delay: 10
              failed_when: false
              loop: "{{ required_operators }}"
              loop_control:
                label: "{{ item.name }}"

            - name: Verify operator CSV final status
              k8s_info:
                api_version: operators.coreos.com/v1alpha1
                kind: ClusterServiceVersion
                namespace: "{{ item.namespace }}"
              register: csv_final_check
              failed_when: false
              loop: "{{ required_operators }}"
              loop_control:
                label: "{{ item.name }}"

            - name: Check if operator is ready
              set_fact:
                operator_ready: >
                  {{ csv_result.resources | selectattr('metadata.name', 'match', '.*' + csv_result.item.name + '.*') | map(attribute='status.phase') | list | first | default('') == 'Succeeded' }}
              loop: "{{ csv_final_check.results }}"
              loop_control:
                loop_var: csv_result
                index_var: csv_index

            - name: Display operator status
              debug:
                msg:
                  - "Operator: {{ item.item.name }}"
                  - "Namespace: {{ item.item.namespace }}"
                  - "CSV Phase: {{ item.resources | selectattr('metadata.name', 'match', '.*' + item.item.name + '.*') | map(attribute='status.phase') | list | first | default('Not found') }}"
                  - "Ready: {{ item.resources | selectattr('metadata.name', 'match', '.*' + item.item.name + '.*') | map(attribute='status.phase') | list | first | default('') == 'Succeeded' }}"
              loop: "{{ csv_final_check.results }}"
              loop_control:
                label: "{{ item.item.name }}"

            - name: Show CSV details for non-ready operators
              debug:
                msg:
                  - "Operator {{ item.item.name }} ({{ item.item.namespace }}) CSV not Succeeded:"
                  - "  Phase: {{ (matching_csv.get('status') or {}).get('phase', 'No CSV found') }}"
                  - "  Conditions: {{ (matching_csv.get('status') or {}).get('conditions', []) | default([]) | to_nice_json }}"
                  - "  Run: oc get csv -n {{ item.item.namespace }}; oc describe csv -n {{ item.item.namespace }} <csv-name>"
              loop: "{{ csv_final_check.results }}"
              loop_control:
                label: "{{ item.item.name }}"
              vars:
                matching_csv: "{{ (item.resources | selectattr('metadata.name', 'match', '.*' + item.item.name + '.*') | list | first) | default({}) }}"
              when: >
                (item.resources | selectattr('metadata.name', 'match', '.*' + item.item.name + '.*') | map(attribute='status.phase') | list | first | default('')) != 'Succeeded'

            - name: Fail if any operator is not ready
              fail:
                msg: >
                  Operator {{ item.item.name }} in namespace {{ item.item.namespace }} did not reach CSV phase Succeeded (waited up to 10 min).
                  Current phase: {{ item.resources | selectattr('metadata.name', 'match', '.*' + item.item.name + '.*') | map(attribute='status.phase') | list | first | default('Not found') }}
                  Conditions: {{ ((item.resources | selectattr('metadata.name', 'match', '.*' + item.item.name + '.*') | list | first) | default({})).get('status', {}) or {} | to_nice_json }}
                  Check: oc get csv -n {{ item.item.namespace }}; oc describe csv -n {{ item.item.namespace }} <csv-name>
              when: >
                item.resources | selectattr('metadata.name', 'match', '.*' + item.item.name + '.*') | map(attribute='status.phase') | list | first | default('') != 'Succeeded'
              loop: "{{ csv_final_check.results }}"
              loop_control:
                label: "{{ item.item.name }}"

          rescue:
            - name: Display operator installation error details
              debug:
                msg:
                  - "Error waiting for operators to be ready"
                  - "Check operator status with: oc get csv -n <namespace>"
                  - "Check subscriptions with: oc get subscription -n <namespace>"
                  - "Check subscription conditions: oc get subscription <operator-name> -n <namespace> -o yaml | grep -A 10 conditions"
              failed_when: true

        - name: Display operators installation success
          debug:
            msg: "All required operators are installed and ready! Service Mesh (Istio) is installed first; Connectivity Link (rhcl-operator) syncs later (sync_wave 6) so the Gateway API provider is available."

        - name: Clean up duplicate devspaces subscription if exists
          block:
            - name: Check for duplicate devspaces subscriptions
              k8s_info:
                api_version: operators.coreos.com/v1alpha1
                kind: Subscription
                namespace: openshift-operators
              register: all_subscriptions
              failed_when: false

            - name: Find devspaces subscriptions
              set_fact:
                devspaces_subs: >
                  {{ all_subscriptions.resources | selectattr('metadata.name', 'equalto', 'devspaces') | list }}

            - name: Delete duplicate devspaces subscription without startingCSV
              k8s:
                state: absent
                api_version: operators.coreos.com/v1alpha1
                kind: Subscription
                namespace: openshift-operators
                name: devspaces
              when: >
                devspaces_subs | length > 1 or
                (devspaces_subs | length == 1 and
                 devspaces_subs[0].spec.startingCSV | default('') == '')
              register: delete_result
              failed_when: false

            - name: Display cleanup status
              debug:
                msg:
                  - "devspaces subscriptions found: {{ devspaces_subs | length }}"
                  - "Action: {{ 'Deleted duplicate subscription' if delete_result.changed | default(false) else 'No duplicate found or already cleaned' }}"
                  - "Note: The correct subscription should have startingCSV: devspacesoperator.v3.24.0"

        - name: Fix rhbk-operator OperatorGroup if it has AllNamespaces
          block:
            - name: Check if rhbk-operator OperatorGroup exists
              k8s_info:
                api_version: operators.coreos.com/v1alpha2
                kind: OperatorGroup
                namespace: rhbk-operator
                name: rhbk-operator
              register: rhbk_og
              failed_when: false

            - name: Check if OperatorGroup has AllNamespaces (empty spec)
              set_fact:
                has_allnamespaces: >
                  {{ rhbk_og.resources | length > 0 and
                     (rhbk_og.resources[0].spec | default({}) | length == 0 or
                      rhbk_og.resources[0].spec.targetNamespaces | default([]) | length == 0) }}

            - name: Delete and recreate OperatorGroup if it has AllNamespaces
              block:
                - name: Delete existing OperatorGroup with AllNamespaces
                  k8s:
                    state: absent
                    api_version: operators.coreos.com/v1alpha2
                    kind: OperatorGroup
                    namespace: rhbk-operator
                    name: rhbk-operator
                  when: has_allnamespaces | default(false)

                - name: Wait for OperatorGroup deletion
                  pause:
                    seconds: 5
                  when: has_allnamespaces | default(false)

                - name: Create OperatorGroup with targetNamespaces
                  k8s:
                    state: present
                    definition:
                      apiVersion: operators.coreos.com/v1alpha2
                      kind: OperatorGroup
                      metadata:
                        name: rhbk-operator
                        namespace: rhbk-operator
                        annotations:
                          argocd.argoproj.io/sync-wave: "2"
                      spec:
                        targetNamespaces:
                          - rhbk-operator
                  when: has_allnamespaces | default(false)
                  register: create_rhbk_og

            - name: Display OperatorGroup fix status
              debug:
                msg:
                  - "rhbk-operator OperatorGroup status:"
                  - "  - Exists: {{ rhbk_og.resources | length > 0 }}"
                  - "  - Has AllNamespaces: {{ has_allnamespaces | default(false) }}"
                  - "  - Action taken: {{ 'Recreated with targetNamespaces' if has_allnamespaces | default(false) else 'No action needed' }}"
                  - "Note: If the operator CSV still shows AllNamespaces error, you may need to delete the Subscription and let it recreate"

        - name: Remove Connectivity Link ConsoleLink (use dynamic plugin via spec.plugins instead; ConsoleLink can block sync)
          command: oc delete consolelink connectivity-link --ignore-not-found=true
          register: delete_cl_consolelink
          changed_when: delete_cl_consolelink.rc == 0 and 'deleted' in (delete_cl_consolelink.stdout | default(''))
          failed_when: false

        - name: Enable console plugins for GitOps and Connectivity Link (dynamic plugin – Administration → spec.plugins)
          block:
            - name: Create or update GitOps ConsolePlugin (dynamic plugin)
              k8s:
                state: present
                definition:
                  apiVersion: console.openshift.io/v1
                  kind: ConsolePlugin
                  metadata:
                    name: gitops-plugin
                  spec:
                    backend:
                      service:
                        name: openshift-gitops-server
                        namespace: openshift-gitops
                        port: 443
                        basePath: /api/plugin
                    displayName: GitOps
              register: gitops_plugin_result
              failed_when: false

            - name: Create or update Connectivity Link ConsolePlugin (dynamic plugin)
              k8s:
                state: present
                definition:
                  apiVersion: console.openshift.io/v1
                  kind: ConsolePlugin
                  metadata:
                    name: connectivity-link-plugin
                  spec:
                    backend:
                      service:
                        name: neuralbank
                        namespace: neuralbank-stack
                        port: 8080
                        basePath: /api/plugin
                    displayName: Connectivity Link
              register: connectivity_plugin_result
              failed_when: false

            - name: Patch Console operator to enable plugins in sidebar (barra vertical)
              command: >
                oc patch console.operator.openshift.io cluster --type merge
                -p '{"spec":{"plugins":["gitops-plugin","connectivity-link-plugin"]}}'
              register: console_patch_result
              failed_when: false
              changed_when: console_patch_result.rc == 0

            - name: Brief pause for console operator to reconcile
              pause:
                seconds: 10
              when: console_patch_result.rc == 0

            - name: Re-apply console plugins patch (ensure sidebar entries persist)
              command: >
                oc patch console.operator.openshift.io cluster --type merge
                -p '{"spec":{"plugins":["gitops-plugin","connectivity-link-plugin"]}}'
              register: console_patch_retry
              failed_when: false
              changed_when: console_patch_retry.rc == 0
              when: console_patch_result.rc == 0

            - name: Verify plugins are enabled in Console spec
              command: >
                oc get console.operator.openshift.io cluster -o jsonpath='{.spec.plugins}'
              register: console_plugins_actual
              changed_when: false
              failed_when: false

            - name: Display console plugins status (dynamic plugin – activar desde Administration)
              debug:
                msg:
                  - "Connectivity Link se activa con el dynamic plugin (no ConsoleLink)."
                  - "Ver plugins actuales: oc get console.operator.openshift.io cluster -o jsonpath='{.spec.plugins}'"
                  - "Console spec.plugins actual: {{ console_plugins_actual.stdout | default('(no leído)') }}"
                  - "Para activar desde consola: Administration → Cluster Settings → Console → spec.plugins (añadir connectivity-link-plugin)."
                  - "O por CLI: oc patch console.operator.openshift.io cluster --type merge -p '{\"spec\":{\"plugins\":[\"gitops-plugin\",\"connectivity-link-plugin\"]}}'"
              when: console_plugins_actual is defined

    - name: Get NeuralBank OIDC client secret from Keycloak when operational (realm neuralbank, client neuralbank)
      block:
        - name: Patch Keycloak CR with correct cluster hostname (so RHBK instance uses cluster_domain)
          command: >
            oc patch keycloaks.k8s.keycloak.org rhbk -n rhbk-operator --type=merge
            -p '{"spec":{"hostname":{"hostname":"{{ keycloak_host }}"}}}'
          register: keycloak_cr_patch
          changed_when: keycloak_cr_patch.rc == 0
          failed_when: false

        - name: Display Keycloak host used for token (cluster_domain from ingress)
          debug:
            msg: "Using Keycloak host for token: {{ keycloak_host }} (from cluster domain)"

        - name: Get Keycloak admin credentials for NeuralBank realm
          command: >
            oc get secret keycloak-initial-admin -n rhbk-operator
            -o "jsonpath={{ '{.data.username}' }}" | base64 -d
          register: kc_nb_admin_user
          changed_when: false
          failed_when: false

        - name: Get Keycloak admin password for NeuralBank realm
          command: >
            oc get secret keycloak-initial-admin -n rhbk-operator
            -o "jsonpath={{ '{.data.password}' }}" | base64 -d
          register: kc_nb_admin_pass
          changed_when: false
          failed_when: false
          no_log: true

        - name: Get Keycloak admin token for NeuralBank API calls
          uri:
            url: "https://{{ keycloak_host }}/realms/master/protocol/openid-connect/token"
            method: POST
            body_format: form-urlencoded
            body:
              grant_type: password
              client_id: admin-cli
              username: "{{ kc_nb_admin_user.stdout }}"
              password: "{{ kc_nb_admin_pass.stdout }}"
            return_content: true
            status_code: [200]
            validate_certs: false
          register: kc_nb_token_result
          retries: 12
          delay: 10
          until: kc_nb_token_result.status == 200 and (kc_nb_token_result.json | default({})).access_token | length > 0
          failed_when: false

        - name: Set Keycloak admin token for NeuralBank
          set_fact:
            kc_nb_access_token: "{{ kc_nb_token_result.json.access_token }}"
          when: kc_nb_token_result.status | default(0) == 200 and (kc_nb_token_result.json | default({})).access_token is defined

        - name: Get neuralbank client UUID from Keycloak realm neuralbank
          uri:
            url: "https://{{ keycloak_host }}/admin/realms/neuralbank/clients?clientId=neuralbank"
            method: GET
            headers:
              Authorization: "Bearer {{ kc_nb_access_token }}"
              Content-Type: application/json
            return_content: true
            status_code: [200]
            validate_certs: false
          register: kc_nb_clients_result
          when: kc_nb_access_token is defined

        - name: Set neuralbank client internal ID
          set_fact:
            kc_nb_client_id: "{{ (kc_nb_clients_result.json | default([{}])[0]).id }}"
          when: >
            kc_nb_clients_result is defined and
            kc_nb_clients_result.json is defined and
            (kc_nb_clients_result.json | length) > 0

        - name: Get neuralbank client secret from Keycloak
          uri:
            url: "https://{{ keycloak_host }}/admin/realms/neuralbank/clients/{{ kc_nb_client_id }}/client-secret"
            method: GET
            headers:
              Authorization: "Bearer {{ kc_nb_access_token }}"
              Content-Type: application/json
            return_content: true
            status_code: [200]
            validate_certs: false
          register: kc_nb_client_secret_result
          when: kc_nb_client_id is defined

        - name: Set NeuralBank OIDC credentials from Keycloak
          set_fact:
            neuralbank_oidc_secret_from_keycloak: true
            oidc_client_id: "neuralbank"
            oidc_client_secret: "{{ kc_nb_client_secret_result.json.value }}"
          when: kc_nb_client_secret_result.json.value is defined

        - name: Replace OIDC_CLIENT_SECRET_PLACEHOLDER in neuralbank-stack/values.yaml
          replace:
            path: "{{ playbook_dir }}/neuralbank-stack/values.yaml"
            regexp: "OIDC_CLIENT_SECRET_PLACEHOLDER"
            replace: "{{ oidc_client_secret }}"
          when: oidc_client_secret is defined

        - name: Replace OIDC_CLIENT_SECRET_PLACEHOLDER in rhcl-operator/oidc-policy.yaml
          replace:
            path: "{{ playbook_dir }}/rhcl-operator/oidc-policy.yaml"
            regexp: "OIDC_CLIENT_SECRET_PLACEHOLDER"
            replace: "{{ oidc_client_secret }}"
          when: oidc_client_secret is defined

        - name: Ensure neuralbank-stack namespace exists for OIDC Secret
          k8s:
            api_version: v1
            kind: Namespace
            name: neuralbank-stack
            state: present
          when: oidc_client_secret is defined

        - name: Create Secret with OIDC credentials in neuralbank-stack (from Keycloak)
          k8s:
            state: present
            definition:
              apiVersion: v1
              kind: Secret
              metadata:
                name: oidc-client-credentials
                namespace: neuralbank-stack
              type: Opaque
              stringData:
                client_id: "{{ oidc_client_id }}"
                client_secret: "{{ oidc_client_secret }}"
          when: oidc_client_secret is defined

        - name: Patch OIDCPolicy with full provider (from Keycloak)
          command: >
            oc patch oidcpolicy neuralbank-oidc -n neuralbank-stack --type merge
            -p '{"spec":{"provider":{
              "issuerURL":"https://{{ keycloak_host }}/realms/neuralbank",
              "clientID":"{{ oidc_client_id }}",
              "clientSecret":"{{ oidc_client_secret }}",
              "authorizationEndpoint":"https://{{ keycloak_host }}/realms/neuralbank/protocol/openid-connect/auth",
              "redirectURI":"https://{{ app_host }}/auth/callback",
              "tokenEndpoint":"https://{{ keycloak_host }}/realms/neuralbank/protocol/openid-connect/token"
            }}}'
          register: oidc_policy_patch_kc
          failed_when: false
          changed_when: oidc_policy_patch_kc.rc == 0
          when: oidc_client_secret is defined

        - name: Write OIDC credentials and keycloak URLs for frontend (from Keycloak)
          copy:
            content: |
              # OIDC credentials for NeuralBank (client secret from Keycloak realm neuralbank, client neuralbank)
              keycloak:
                issuerUrl: 'https://{{ keycloak_host }}/realms/neuralbank'
                clientId: 'neuralbank-frontend'
                clientSecret: '{{ oidc_client_secret }}'
                authorizationEndpoint: 'https://{{ keycloak_host }}/realms/neuralbank/protocol/openid-connect/auth'
                redirectUri: 'https://{{ app_host }}/auth/callback'
                tokenEndpoint: 'https://{{ keycloak_host }}/realms/neuralbank/protocol/openid-connect/token'
                postLogoutRedirectUri: 'https://{{ app_host }}'
            dest: "{{ playbook_dir }}/oidc-credentials-values.yaml"
            mode: '0600'
          when: oidc_client_secret is defined

        - name: Display NeuralBank OIDC from Keycloak summary
          debug:
            msg:
              - "NeuralBank OIDC: client secret obtained from Keycloak (realm neuralbank, client neuralbank)."
              - "  values.yaml and oidc-policy.yaml updated; OIDCPolicy patched; Secrets and oidc-credentials-values.yaml written."
              - "  Commit and push so ArgoCD syncs the updated values."
          when: oidc_client_secret is defined
      rescue:
        - name: NeuralBank OIDC from Keycloak not available
          debug:
            msg: "Keycloak or realm neuralbank not ready yet. Fallback OIDC block will use env OIDC_CLIENT_ID/OIDC_CLIENT_SECRET or generate; re-run playbook after Keycloak is up to get secret from Keycloak."
          failed_when: false
      when: keycloak_host is defined and app_host is defined

    - name: Create OIDC client credentials for OIDCPolicy and frontend (fallback when Keycloak secret not used)
      when: neuralbank_oidc_secret_from_keycloak is not defined
      block:
        - name: Set OIDC client ID from env or default
          set_fact:
            oidc_client_id: "{{ lookup('env', 'OIDC_CLIENT_ID') | default('neuralbank-frontend', true) }}"

        - name: Generate random OIDC client secret when not provided
          command: openssl rand -base64 24
          register: oidc_secret_gen
          changed_when: false
          when: lookup('env', 'OIDC_CLIENT_SECRET') | length == 0

        - name: Set OIDC client secret (from env or generated)
          set_fact:
            oidc_client_secret: "{{ lookup('env', 'OIDC_CLIENT_SECRET') if lookup('env', 'OIDC_CLIENT_SECRET') else oidc_secret_gen.stdout }}"

        - name: Ensure neuralbank-stack namespace exists for OIDC Secret
          k8s:
            api_version: v1
            kind: Namespace
            name: neuralbank-stack
            state: present

        - name: Create Secret with OIDC credentials in neuralbank-stack (frontend)
          k8s:
            state: present
            definition:
              apiVersion: v1
              kind: Secret
              metadata:
                name: oidc-client-credentials
                namespace: neuralbank-stack
              type: Opaque
              stringData:
                client_id: "{{ oidc_client_id }}"
                client_secret: "{{ oidc_client_secret }}"

        - name: Create Secret with OIDC credentials in neuralbank-stack (OIDCPolicy fallback)
          k8s:
            state: present
            definition:
              apiVersion: v1
              kind: Secret
              metadata:
                name: oidc-client-credentials
                namespace: neuralbank-stack
              type: Opaque
              stringData:
                client_id: "{{ oidc_client_id }}"
                client_secret: "{{ oidc_client_secret }}"

        - name: Patch OIDCPolicy with client ID and client secret
          command: >
            oc patch oidcpolicy neuralbank-oidc -n neuralbank-stack --type merge
            -p '{"spec":{"provider":{"clientID":"{{ oidc_client_id }}","clientSecret":"{{ oidc_client_secret }}"}}}'
          register: oidc_policy_patch
          failed_when: false
          changed_when: oidc_policy_patch.rc == 0

        - name: Write OIDC credentials snippet for frontend Helm values
          copy:
            content: |
              # OIDC credentials for NeuralBank frontend (generated by install-gitops)
              # Use as Helm value override: helm upgrade ... -f oidc-credentials-values.yaml
              # or set in neuralbank-stack/values.yaml / Application valueFiles
              keycloak:
                clientId: "{{ oidc_client_id }}"
                clientSecret: "{{ oidc_client_secret }}"
            dest: "{{ playbook_dir }}/oidc-credentials-values.yaml"
            mode: '0600'

        - name: Display OIDC credentials summary
          debug:
            msg:
              - "OIDC client credentials created/updated:"
              - "  Client ID: {{ oidc_client_id }}"
              - "  Client secret: (stored in Secrets and oidc-credentials-values.yaml)"
              - "  Secret 'oidc-client-credentials' in namespace: neuralbank-stack"
              - "  OIDCPolicy neuralbank-oidc (neuralbank-stack): {{ 'patched' if oidc_policy_patch.rc == 0 else 'not found or patch failed (sync OIDCPolicy first)' }}"
              - "  Frontend: use keycloak.clientId and keycloak.clientSecret from {{ playbook_dir }}/oidc-credentials-values.yaml in neuralbank-stack values"
              - "  To provide your own: set env OIDC_CLIENT_ID and OIDC_CLIENT_SECRET before running install"
      rescue:
        - name: Display OIDC credentials block error
          debug:
            msg: "OIDC credentials block failed (namespaces or OIDCPolicy may not exist yet). Create client in Keycloak and set OIDC_CLIENT_ID / OIDC_CLIENT_SECRET, then re-run."
          failed_when: false

    - name: Generate Developer Hub (RHDH) secrets from Keycloak when operational
      block:
        - name: Ensure developer-hub namespace exists
          k8s:
            api_version: v1
            kind: Namespace
            name: developer-hub
            state: present

        - name: Get Keycloak admin credentials from secret (rhbk-operator)
          command: >
            oc get secret keycloak-initial-admin -n rhbk-operator
            -o "jsonpath={{ '{.data.username}' }}" | base64 -d
          register: kc_admin_user
          changed_when: false
          failed_when: false

        - name: Get Keycloak admin password from secret
          command: >
            oc get secret keycloak-initial-admin -n rhbk-operator
            -o "jsonpath={{ '{.data.password}' }}" | base64 -d
          register: kc_admin_pass
          changed_when: false
          failed_when: false
          no_log: true

        - name: Wait for Keycloak admin API and get token
          uri:
            url: "https://{{ keycloak_host }}/realms/master/protocol/openid-connect/token"
            method: POST
            body_format: form-urlencoded
            body:
              grant_type: password
              client_id: admin-cli
              username: "{{ kc_admin_user.stdout }}"
              password: "{{ kc_admin_pass.stdout }}"
            return_content: true
            status_code: [200]
            validate_certs: false
          register: kc_token_result
          retries: 12
          delay: 10
          until: kc_token_result.status == 200 and (kc_token_result.json | default({})).access_token | length > 0
          failed_when: false

        - name: Set Keycloak admin token
          set_fact:
            kc_access_token: "{{ kc_token_result.json.access_token }}"
          when: kc_token_result.status | default(0) == 200 and (kc_token_result.json | default({})).access_token is defined

        - name: Get backstage client UUID from Keycloak realm
          uri:
            url: "https://{{ keycloak_host }}/admin/realms/backstage/clients?clientId=backstage"
            method: GET
            headers:
              Authorization: "Bearer {{ kc_access_token }}"
              Content-Type: application/json
            return_content: true
            status_code: [200]
            validate_certs: false
          register: kc_clients_result
          when: kc_access_token is defined

        - name: Set backstage client internal ID
          set_fact:
            kc_backstage_client_id: "{{ (kc_clients_result.json | default([{}])[0]).id }}"
          when: >
            kc_clients_result is defined and
            kc_clients_result.json is defined and
            (kc_clients_result.json | length) > 0

        - name: Get backstage client secret from Keycloak
          uri:
            url: "https://{{ keycloak_host }}/admin/realms/backstage/clients/{{ kc_backstage_client_id }}/client-secret"
            method: GET
            headers:
              Authorization: "Bearer {{ kc_access_token }}"
              Content-Type: application/json
            return_content: true
            status_code: [200]
            validate_certs: false
          register: kc_client_secret_result
          when: kc_backstage_client_id is defined

        - name: Set RHDH Keycloak and URL variables
          set_fact:
            rhdh_keycloak_realm: "backstage"
            rhdh_keycloak_client_id: "backstage"
            rhdh_client_id: "backstage"
            rhdh_keycloak_client_secret: "{{ kc_client_secret_result.json.value }}"
            rhdh_keycloak_base_url: "https://{{ keycloak_host }}"
            rhdh_keycloak_metadata_url: "https://{{ keycloak_host }}/realms/backstage/.well-known/openid-configuration"
            rhdh_host: "backstage-developer-hub-developer-hub.{{ apps_domain }}"
            rhdh_base_url: "https://backstage-developer-hub-developer-hub.{{ apps_domain }}"
            rhdh_callback_url: "https://backstage-developer-hub-developer-hub.{{ apps_domain }}/api/auth/oidc/handler/frame"
          when: kc_client_secret_result.json.value is defined

        - name: Generate random BACKEND_SECRET and ADMIN_TOKEN for RHDH
          command: openssl rand -base64 16
          register: rhdh_backend_secret_gen
          changed_when: false
          when: rhdh_keycloak_client_secret is defined

        - name: Set RHDH backend and admin tokens
          set_fact:
            rhdh_backend_secret: "{{ rhdh_backend_secret_gen.stdout }}"
            rhdh_admin_token: "{{ rhdh_backend_secret_gen.stdout }}"
            rhdh_mcp_token: "backstage"
          when: rhdh_backend_secret_gen.stdout is defined

        - name: Set optional OLLAMA placeholders for RHDH secret
          set_fact:
            rhdh_ollama_token: ""
            rhdh_ollama_url: "http://ollama:11434"
          when: rhdh_backend_secret is defined

        - name: Create Developer Hub secret in cluster
          k8s:
            state: present
            definition:
              apiVersion: v1
              kind: Secret
              metadata:
                name: secrets-rhdh
                namespace: developer-hub
              type: Opaque
              stringData:
                KEYCLOAK_CLIENT_ID: "{{ rhdh_keycloak_client_id }}"
                KEYCLOAK_REALM: "{{ rhdh_keycloak_realm }}"
                KEYCLOAK_CLIENT_SECRET: "{{ rhdh_keycloak_client_secret }}"
                CLIENT_ID: "{{ rhdh_client_id }}"
                CLIENT_SECRET: "{{ rhdh_keycloak_client_secret }}"
                KEYCLOAK_BASE_URL: "{{ rhdh_keycloak_base_url }}"
                KEYCLOAK_METADATA_URL: "{{ rhdh_keycloak_metadata_url }}"
                RHDH_BASE_URL: "{{ rhdh_base_url }}"
                RHDH_CALLBACK_URL: "{{ rhdh_callback_url }}"
                BACKEND_SECRET: "{{ rhdh_backend_secret }}"
                ADMIN_TOKEN: "{{ rhdh_admin_token }}"
                MCP_TOKEN: "{{ rhdh_mcp_token }}"
                OLLAMA_TOKEN: "{{ rhdh_ollama_token | default('') }}"
                OLLAMA_URL: "{{ rhdh_ollama_url | default('') }}"
          when: rhdh_backend_secret is defined

        - name: Render RHDH secret manifest to file (gitignored)
          template:
            src: developer-hub/secret-secrets-rhdh.yaml.j2
            dest: "{{ playbook_dir }}/developer-hub/secret-secrets-rhdh.generated.yaml"
            mode: '0600'
          when: rhdh_backend_secret is defined

        - name: Display RHDH secrets summary
          debug:
            msg:
              - "Developer Hub secret 'secrets-rhdh' created/updated in namespace developer-hub."
              - "  Keycloak realm: {{ rhdh_keycloak_realm }}, client: {{ rhdh_keycloak_client_id }}"
              - "  RHDH base URL: {{ rhdh_base_url }}"
              - "  Manifest (do not commit): {{ playbook_dir }}/developer-hub/secret-secrets-rhdh.generated.yaml"
          when: rhdh_backend_secret is defined
      rescue:
        - name: Display RHDH secrets block error
          debug:
            msg: "Developer Hub secrets block failed (Keycloak may not be ready or backstage realm/client missing). Ensure Keycloak is up and realm 'backstage' with client 'backstage' exists, then re-run install."
          failed_when: false
