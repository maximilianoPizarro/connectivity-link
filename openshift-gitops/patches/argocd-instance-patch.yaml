apiVersion: argoproj.io/v1alpha1
kind: ArgoCD
metadata:
  name: openshift-gitops
  namespace: openshift-gitops
  annotations:
    argocd.argoproj.io/sync-wave: "0"
spec:
  # Application Controller: más recursos para evitar OOMKilled con muchas apps/ApplicationSets.
  # Opcional: spec.ha.enabled: true para Redis HA si usas varias réplicas en producción.
  controller:
    resources:
      limits:
        cpu: "2"
        memory: 4Gi
      requests:
        cpu: 500m
        memory: 1Gi
    # Réplicas para que un fallo no deje GitOps sin controller
    sharding:
      enabled: true
      replicas: 2
  # Habilitar ApplicationSet controller
  applicationSet:
    resources:
      limits:
        cpu: "2"
        memory: 1Gi
      requests:
        cpu: 250m
        memory: 512Mi
  # Habilitar autenticación OAuth nativa de OpenShift
  sso:
    provider: dex
    dex:
      openShiftOAuth: true
  rbac:
    defaultPolicy: ''
    policy: |
      g, system:cluster-admins, role:admin
      g, cluster-admins, role:admin
      g, system:authenticated, role:admin
      g, system:authenticated:oauth, role:admin
    scopes: '[groups]'
  # Repo server: más recursos y réplicas para evitar timeouts y "connection refused" al generar manifiestos
  repo:
    resources:
      limits:
        cpu: "2"
        memory: 2Gi
      requests:
        cpu: 250m
        memory: 512Mi
    replicas: 2
    # Opciones del Repositorio (Aquí se monta el CMP)
    sidecarContainers:
      - name: my-custom-plugin-sidecar
        command: [/var/run/argocd/argocd-cmp-server]
        image: registry.redhat.io/openshift-gitops-1/argocd-rhel8:latest
        securityContext:
          runAsNonRoot: true
          runAsUser: 999
        volumeMounts:
          - mountPath: /var/run/argocd
            name: var-files
          - mountPath: /home/argocd/cmp-server/plugins
            name: plugins
          # Montamos el ConfigMap que creamos en el paso 3
          - mountPath: /home/argocd/cmp-server/config/plugin.yaml
            name: my-custom-plugin
            subPath: plugin.yaml

    volumes:
      - configMap:
          name: my-custom-plugin
        name: my-custom-plugin

  # Configuraciones globales adicionales
  resourceCustomizations: |
    # Ejemplo: Solucionar problemas de salud en PVCs o CRDs raros
    "*.k8s.io/PersistentVolumeClaim":
      health.lua: |
        hs = {}
        if obj.status ~= nil and obj.status.phase == "Bound" then
          hs.status = "Healthy"
          hs.message = "Volume is bound"
        else
          hs.status = "Progressing"
          hs.message = "Waiting for volume"
        end
        return hs
    # OpenShift Route: Healthy when it exists (avoids blocking servicemeshoperator3 app when Route has no status.ingress)
    "route.openshift.io/Route":
      health.lua: |
        hs = {}
        if obj.status ~= nil and obj.status.ingress ~= nil and #obj.status.ingress > 0 then
          hs.status = "Healthy"
          hs.message = "Route admitted"
        else
          hs.status = "Healthy"
          hs.message = "Route created"
        end
        return hs
    # Service: Healthy when it exists (avoids "waiting for healthy state of /Service/postgres-db" in rhbk app while the pod is starting)
    "core/Service":
      health.lua: |
        hs = {}
        hs.status = "Healthy"
        hs.message = "Service exists"
        return hs